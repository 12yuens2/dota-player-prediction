{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action_df(raw_df, action):\n",
    "    return raw_df.loc[raw_df[\"actionType\"] == action].drop(\"actionType\", 1)\n",
    "\n",
    "def get_action_dfs(csvpath, dropna=True):\n",
    "    raw_df = pd.read_csv(csvpath)\n",
    "    if dropna:\n",
    "        raw_df = raw_df.dropna()\n",
    "    \n",
    "    attack_df = get_action_df(raw_df, \"ATTACK\")\n",
    "    move_df = get_action_df(raw_df, \"MOVE\")\n",
    "    cast_df = get_action_df(raw_df, \"CAST\")\n",
    "\n",
    "    return [attack_df, move_df, cast_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def get_df(file0, file1, splits):\n",
    "    dfs0 = [get_stats(df, 0, splits) for df in get_action_dfs(file0)]\n",
    "    dfs1 = [get_stats(df, 1, splits) for df in get_action_dfs(file1)]\n",
    "    \n",
    "    dfs = []\n",
    "    for i in range(len(dfs0)):\n",
    "        df0 = dfs0[i]\n",
    "        df1 = dfs1[i]\n",
    "        \n",
    "        df0[\"tmp\"] = 1\n",
    "        df1[\"tmp\"] = 1\n",
    "\n",
    "        dfs.append(pd.merge(df0, df1, how=\"inner\").drop(\"tmp\", 1))\n",
    "    \n",
    "    return dfs\n",
    "    \n",
    "    \n",
    "def get_stats(raw_df, fid, splits):\n",
    "    i = 0\n",
    "    data = []\n",
    "    headers = []\n",
    "    for df in split_df(raw_df, splits):\n",
    "        stats = df.describe().drop(\"count\", 0).drop(\"steamid\", 1).fillna(0)\n",
    "        headers.extend(get_headers(stats, fid, i))\n",
    "        data.extend(get_data(stats))\n",
    "        i += 1\n",
    "       \n",
    "    df = pd.DataFrame(data=[data],columns=headers)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def split_df(df, splits):\n",
    "    rows = int(math.ceil(len(df.index)/float(splits)))\n",
    "    dfs = []\n",
    "    \n",
    "    while len(df) > rows:\n",
    "        tmp = df[:rows]\n",
    "        dfs.append(tmp)\n",
    "        df = df[rows:]\n",
    "    else:\n",
    "        dfs.append(df)\n",
    "\n",
    "    return dfs    \n",
    "\n",
    "\n",
    "def get_headers(stats, fid, i):\n",
    "    return [\n",
    "        \"{}-{}-{}-{}\".format(stats.columns[col],stats.index[row], fid, i) \n",
    "        for row in range(len(stats.index)) \n",
    "        for col in range(len(stats.columns.values))\n",
    "    ]\n",
    "\n",
    "def get_data(stats):\n",
    "    return [\n",
    "        stats.iloc[row,col]\n",
    "        for row in range(len(stats.index))\n",
    "        for col in range(len(stats.columns.values))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import ntpath\n",
    "\n",
    "def get_pairs(path):\n",
    "    files = [\"{}/{}\".format(path, file) for file in os.listdir(path)]\n",
    "    return list(itertools.permutations(files, 2))\n",
    "\n",
    "def get_playerid(name):\n",
    "    return ntpath.basename(name)[:17]\n",
    "\n",
    "def is_same_player(id1, id2):\n",
    "    return 1 if id1 == id2 else 0\n",
    "\n",
    "def get_ys(pairs):\n",
    "    return [\n",
    "        is_same_player(get_playerid(file0), get_playerid(file1))\n",
    "        for file0,file1 in pairs\n",
    "    ]\n",
    "\n",
    "def get_pair_dfs(pairs, splits):\n",
    "    attacks, moves, casts = [],[],[]\n",
    "    for file0, file1 in pairs:\n",
    "        dfs = get_df(file0, file1, splits)\n",
    "        \n",
    "        attacks.append(dfs[0])\n",
    "        moves.append(dfs[1])\n",
    "        casts.append(dfs[2])\n",
    "        \n",
    "    return pd.concat(attacks), pd.concat(moves), pd.concat(casts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "def train(df, ys):\n",
    "    lr = LogisticRegression(class_weight=\"balanced\")\n",
    "    lr.fit(df, ys)\n",
    "\n",
    "    rf = RandomForestClassifier(class_weight=\"balanced\")\n",
    "    rf.fit(df, ys)\n",
    "    \n",
    "    nn = MLPClassifier(solver=\"lbfgs\", alpha=0.01)\n",
    "    nn.fit(df, ys)\n",
    "    \n",
    "    return lr, rf, nn\n",
    "\n",
    "def test(model, df, y):\n",
    "    predictions = model.predict(df)\n",
    "    \n",
    "    accuracy = accuracy_score(y, predictions)\n",
    "    precision = precision_score(y, predictions)\n",
    "    recall = recall_score(y, predictions)\n",
    "    \n",
    "    print_scores(type(model).__name__, accuracy, precision, recall)\n",
    "    \n",
    "    return accuracy, precision, recall\n",
    "\n",
    "def print_scores(name, accuracy, precision, recall):\n",
    "    print(\"{} - Accuracy: {}, Precision: {}, Recall: {}\".format(name, accuracy, precision, recall)) \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def sample_filter(sample, prob):\n",
    "    if sample[1] == 0:\n",
    "        if random.random() < prob:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def sample(X, y, prob):\n",
    "    combine = [(X[i], y[i]) for i in range(len(X))]\n",
    "    sample = [s for s in combine if not sample_filter(s, prob)]\n",
    "    \n",
    "    return map(list, zip(*sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def count_sample(x):\n",
    "    negatives = x.count(0)\n",
    "    positives = x.count(1)\n",
    "    return \"{} negative samples and {} positive samples\".format(negatives, positives)\n",
    "\n",
    "\n",
    "def standardise(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    \n",
    "    return scaler.transform(X_train), scaler.transform(X_test)\n",
    "    \n",
    "\n",
    "def ml(path, splits, sample_ratio):\n",
    "    scaler = StandardScaler()\n",
    "    pairs = get_pairs(path)\n",
    "    ys = get_ys(pairs)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(pairs, ys, test_size=0.2, stratify=ys)\n",
    "    X_train, y_train = sample(X_train, y_train, sample_ratio)\n",
    "    X_test, y_test = sample(X_test, y_test, sample_ratio)\n",
    "    \n",
    "    print(\"Training - {}\".format(count_sample(y_train)))\n",
    "    print(\"Testing - {}\".format(count_sample(y_test)))\n",
    "\n",
    "    for train_df, test_df, action in zip(get_pair_dfs(X_train, splits), get_pair_dfs(X_test, splits), [\"ATTACK\", \"CAST\", \"MOVE\"]):\n",
    "        print(action)\n",
    "        train_df, test_df = standardise(train_df, test_df)\n",
    "\n",
    "        lr, rf, nn = train(train_df, y_train)\n",
    "        test(lr, test_df, y_test)\n",
    "        test(rf, test_df, y_test)\n",
    "        test(nn, test_df, y_test)\n",
    "    print(\"---\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - 14 negative samples and 9 positive samples\n",
      "Testing - 3 negative samples and 3 positive samples\n",
      "ATTACK\n",
      "LogisticRegression - Accuracy: 0.833333333333, Precision: 0.75, Recall: 1.0\n",
      "RandomForestClassifier - Accuracy: 0.5, Precision: 0.0, Recall: 0.0\n",
      "MLPClassifier - Accuracy: 1.0, Precision: 1.0, Recall: 1.0\n",
      "CAST\n",
      "LogisticRegression - Accuracy: 0.833333333333, Precision: 0.75, Recall: 1.0\n",
      "RandomForestClassifier - Accuracy: 0.666666666667, Precision: 0.666666666667, Recall: 0.666666666667\n",
      "MLPClassifier - Accuracy: 0.5, Precision: 0.5, Recall: 0.333333333333\n",
      "MOVE\n",
      "LogisticRegression - Accuracy: 0.833333333333, Precision: 0.75, Recall: 1.0\n",
      "RandomForestClassifier - Accuracy: 0.333333333333, Precision: 0.0, Recall: 0.0\n",
      "MLPClassifier - Accuracy: 0.833333333333, Precision: 0.75, Recall: 1.0\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "ml(\"/cs/scratch/sy35/dota-data/tmp\", 3, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/cs/scratch/sy35/dota-data/14-mouseaction.csv\").drop(\"actionType\", 1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "preproc = Pipeline([\n",
    "    (\"feature_selection\", PCA()),\n",
    "    (\"standardisation\", StandardScaler())\n",
    "])\n",
    "\n",
    "clf = Pipeline([\n",
    "    # \n",
    "    (\"preprocessing\", preproc),\n",
    "    \n",
    "    # Learning\n",
    "    (\"classifier\", LogisticRegression(class_weight=\"balanced\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.32279605, -0.10393854,  3.15177178, ...,  1.05176267,\n",
       "         0.26479506, -0.07871237],\n",
       "       [ 1.32279605, -0.10393854,  3.15177178, ...,  1.05176267,\n",
       "         0.26479506, -0.07871237],\n",
       "       [ 1.32279605,  0.1444993 ,  3.45986189, ...,  0.96094588,\n",
       "         0.5646299 , -0.18546485],\n",
       "       ...,\n",
       "       [-0.82552376, -0.5544113 ,  0.91358539, ...,  0.77335063,\n",
       "         1.47696555, -0.75466931],\n",
       "       [-0.82552376, -0.5544113 ,  0.91358539, ...,  0.77335063,\n",
       "         1.47696555, -0.75466931],\n",
       "       [-0.82552376, -0.59828206, -0.51220148, ...,  0.78132467,\n",
       "         0.9869663 , -0.54915021]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preproc.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('preprocessing', Pipeline(memory=None,\n",
       "     steps=[('feature_selection', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('standardisation', StandardScaler(copy=True, with_mean=True, with_std=True))])), ('classifier', ...ty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ml(\"/cs/scratch/sy35/dota-data/15-1/data/mouseaction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training - 369 negative samples and 203 positive samples\n",
      "Testing - 83 negative samples and 51 positive samples\n"
     ]
    }
   ],
   "source": [
    "ml(\"/cs/scratch/sy35/dota-data/tmp\", 3, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/cs/scratch/sy35/dota-data/15-1/data/mouseaction\"\n",
    "pairs = get_pairs(path)\n",
    "ys = get_ys(pairs)\n",
    "splits = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = sample(pairs, ys, 0.015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'343 negative samples and 254 positive samples'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_sample(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([\n",
    "    # \n",
    "    (\"preprocessing\", preproc),\n",
    "    \n",
    "    # Learning\n",
    "    (\"classifier\", LogisticRegression(class_weight=\"balanced\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATTACK\n",
      "Pipeline - Accuracy: 0.47, Precision: 0.407079646018, Recall: 0.541176470588\n",
      "CAST\n",
      "Pipeline - Accuracy: 0.53, Precision: 0.451612903226, Recall: 0.494117647059\n",
      "MOVE\n",
      "Pipeline - Accuracy: 0.51, Precision: 0.448818897638, Recall: 0.670588235294\n",
      "---\n",
      "ATTACK\n",
      "Pipeline - Accuracy: 0.447236180905, Precision: 0.40157480315, Recall: 0.6\n",
      "CAST\n",
      "Pipeline - Accuracy: 0.48743718593, Precision: 0.406593406593, Recall: 0.435294117647\n",
      "MOVE\n",
      "Pipeline - Accuracy: 0.532663316583, Precision: 0.455555555556, Recall: 0.482352941176\n",
      "---\n",
      "ATTACK\n",
      "Pipeline - Accuracy: 0.515151515152, Precision: 0.441176470588, Recall: 0.535714285714\n",
      "CAST\n",
      "Pipeline - Accuracy: 0.454545454545, Precision: 0.392857142857, Recall: 0.52380952381\n",
      "MOVE\n",
      "Pipeline - Accuracy: 0.530303030303, Precision: 0.449438202247, Recall: 0.47619047619\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(3)\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train = [X[i] for i in train_index]\n",
    "    X_test = [X[i] for i in test_index]\n",
    "    y_train = [y[i] for i in train_index]\n",
    "    y_test = [y[i] for i in test_index]\n",
    "    \n",
    "    for train_df, test_df, action in zip(get_pair_dfs(X_train, splits), get_pair_dfs(X_test, splits), [\"ATTACK\", \"CAST\", \"MOVE\"]):\n",
    "        print(action)\n",
    "        clf = clf.fit(train_df, y_train)\n",
    "        test(clf, test_df, y_test)\n",
    "        \n",
    "        #lr, rf, nn = train(train_df, y_train)\n",
    "        #test(lr, test_df, y_test)\n",
    "        #test(rf, test_df, y_test)\n",
    "        #test(nn, test_df, y_test)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "def get_pair_dfs(self, pair, splits):\n",
    "        attacks, moves, casts = [], [], []\n",
    "        file0, file1 = pair\n",
    "        \n",
    "        dfs = get_df(file0, file1, splits)\n",
    "        \n",
    "        return dfs[0], dfs[1], dfs[2]\n",
    "\n",
    "class Pair:\n",
    "    def __init__(self, pair, splits):\n",
    "        attack_df, move_df, cast_df = get_pair_dfs(pair, splits)\n",
    "        \n",
    "        self.attack_df = attack_df\n",
    "        self.move_df = move_df\n",
    "        self.cast_df = cast_df\n",
    "        \n",
    "\n",
    "class PairClassifier:\n",
    "    \n",
    "    def __init__(self, attack_model, move_model, cast_model, network_size):\n",
    "        self.attack_model = attack_model\n",
    "        self.move_model = move_model\n",
    "        self.cast_model = cast_model\n",
    "        \n",
    "        self.network = MLPClassifier(solver=\"lbfgs\", hidden_layer_sizes=network_size, random_state=42)\n",
    "        \n",
    "    def get_pairs_dfs(self, pairs, splits):\n",
    "        attacks, moves, casts = [], [], []\n",
    "        for pair in pairs:\n",
    "            attacks.append(pair.attack_df)\n",
    "            moves.append(pair.move_df)\n",
    "            casts.append(pair.cast_df)\n",
    "            \n",
    "        return pd.concat(attacks), pd.concat(moves). pd.concat(casts)\n",
    "        \n",
    "    def train(self, pairs, y, splits):\n",
    "        for model, train_df in self.get_pairs_dfs(pairs, splits):\n",
    "            model.fit(train_df, y)\n",
    "        self.fit_network(pairs, y)\n",
    "        \n",
    "    def fit_network(self, pairs, y):\n",
    "        X = [self.get_all_probas(pair) for pair in pairs]\n",
    "        self.network.fit(X, y)\n",
    "        \n",
    "    def get_proba(self, model, df):\n",
    "        return model.predict_proba(df)\n",
    "        \n",
    "    def get_all_probas(self, pair):\n",
    "        attack_proba = self.get_proba(self.attack_model, pair.attack_df)\n",
    "        move_proba = self.get_proba(self.move_model, pair.move_df)\n",
    "        cast_proba = self.get_proba(self.cast_model, pair.cast_df)\n",
    "        \n",
    "        return [attack_proba[1], move_proba[1], cast_proba[1]]\n",
    "        \n",
    "    def predict(self, pairs):\n",
    "        probabilities = [self.get_all_probas(pair) for pair in pairs]\n",
    "        return self.network.predict(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/cs/scratch/sy35/dota-data/tmp\"\n",
    "pairs = get_pairs(path)\n",
    "ys = get_ys(pairs)\n",
    "splits = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = sample(pairs, ys, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = PairClassifier(LogisticRegression(), LogisticRegression(), LogisticRegression(), (3,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'attack_df'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-29ea0fc56d8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-952af24b016f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, pairs, y, splits)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_pairs_dfs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-952af24b016f>\u001b[0m in \u001b[0;36mget_pairs_dfs\u001b[0;34m(self, pairs, splits)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mattacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmoves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpair\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mattacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattack_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mmoves\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmove_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mcasts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'attack_df'"
     ]
    }
   ],
   "source": [
    "pc.train(X, y, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dota",
   "language": "python",
   "name": "dota"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
