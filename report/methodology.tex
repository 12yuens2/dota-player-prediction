\documentclass[Report.tex]{subfiles}

\begin{document}

\section{Methodology}\label{sec:methodology}
This section describes the methodology of each part of the project, explaining the design decisions and illustrating their details. Most notably, the reasoning behind the different subsets of features, how they are extracted from match replays and the process for data collection are discussed.

\subsection{Mouse movement features}\label{sec:mm-features}
The mouse movement features extracted from the Dota 2 replays followed the approach by Feher et al \cite{mouse-dynamics} on user identification via mouse dynamics. Their methodology was to split the mouse movements into different types of actions, such as mouse movement followed by left click, mouse movement followed by drag etc. The concept of lower and higher level actions are also used to differentiate between atomic actions such as a left click or mouse move and more complex actions made up of atomic actions such as mouse drag, which consists of left click down, mouse movement and left click up actions in order. This approach was adapted to the data available from the Dota 2 replays, which is less precise than what could be normally measured as user input. 

There was a significant lack of precision in the data retrieved using the parser on a replay, especially when compared to direct recording of user mouse movements. For example, with live recording of mouse movements, multiple events and features can be extracted from a single mouse click: left click up event, left click down event, click time (the time between click up and click down events) and distanced travelled during the click. From the replay, the clicks themselves are not registered, only the positions of the cursor and the time the commands are received by the user. This limits the number of features that can be generated compared to directly recording mouse events.

While multiple levels of mouse actions are defined by Feher et al \cite{mouse-dynamics}, only two are defined in this project: \textbf{Level 1 actions} and \textbf{Level 3 actions}.

Four \textbf{level 1 actions} are defined, they are:
\begin{itemize}
\item Mouse movement sequence (MM)
\item Attack command (AC)
\item Move command (MC)
\item Spell cast command (SC)
\end{itemize}
A mouse movement sequence is defined as a sequence of positions of the cursor. Rather than using a fixed interval of time in which the sequence must fit, a threshold $\tau$ is used to end the sequence if no change in cursor position has occurred within the time of the threshold. This more naturally records a sequence of mouse movements that doesn't break up a sequence of movements to fit within a fixed time interval. A larger threshold increases the average length of MM actions as more mouse positions are included into the sequence. 

Each MM action consists of three vectors:
\begin{itemize}
\item $\boldsymbol{t} = \{t_i\}^{n}_{i=1}$ - The game tick
\item $\boldsymbol{x} = \{x_i\}^{n}_{i=1}$ - The x coordinate sampled on game tick $t_i$
\item $\boldsymbol{y} = \{y_i\}^{n}_{i=1}$ - The y coordinate sampled on game tick $t_i$
\end{itemize}
The length $i$ is the same across the three vectors, but each MM action can have varying values of $i$. The vectors themselves are further processed to give the following list of basic movement features, based on the approach described by Gamboa et al \cite{mouse-features}:
\begin{table}[H]
\renewcommand*{\arraystretch}{2.5}
\centering
\begin{tabular}{| c | c | c |}
\hline
& \textbf{Feature} & \textbf{Definition} \\ \hline
1 & Angle of movement & $\theta_i = arctan(\dfrac{\delta y_1}{\delta x_1}) + \sum\limits_{j=1}^{i} \delta \theta_j$ \\ \hline
2 & Curvature & $c = \dfrac{\delta\theta}{\delta s}$ \\ \hline
3 & Rate of change of curvature & $\Delta c = \dfrac{\delta c}{\delta s}$ \\ \hline
4 & Horizontal velocity & $V_x = \dfrac{\delta x}{\delta t}$ \\ \hline
5 & Vertical velocity & $V_y = \dfrac{\delta y}{\delta t}$ \\ \hline
6 & Velocity & $V = \sqrt{\delta V_{x}^{2} + \delta V_{y}^{2}}$ \\ \hline
7 & Acceleration & $V' = \dfrac{\delta V}{\delta t}$ \\ \hline
8 & Jerk & $V'' = \dfrac{\delta V'}{\delta t}$ \\ \hline
9 & Angular velocity & $w = \dfrac{\delta \theta_t}{\delta t}$ \\ \hline
\end{tabular}
\caption{Basic mouse movement features used in \cite{mouse-features}}
\label{tbl:mm-features}
\end{table}

Next, the basic features are extracted into the statistics: minimum, maximum, mean and standard deviation. This was done because each of the basic features are vectors of varying length. For example, features such as velocity and curvature have $n + 1$ data points compared to their derivative features. Taking statistics of these vectors eliminates the problem with varied length features, but causes some data to be lost in the conversion.

The combination of a MM action followed by a command action defines the \textbf{level 3 actions}:
\begin{itemize}
\item Mouse movement sequence followed by an attack command (MMAC)
\item Mouse movement sequence followed by a move command (MMMC)
\item Mouse movement sequence followed by a spell cast command (MMSC)
\end{itemize}
To create the three level 3 actions, the parser listens for attack, move and spell cast commands. If a command is recorded, the current MM sequence is used as the sequence leading up to the command. As such, these three features are identical in the way they are recorded, but potentially record very different kinds of data. For example, the move command is sent much more often than the other two commands. The features of the level 3 actions are statistics of the features in table \ref{tbl:mm-features} with two additional features:
\begin{itemize}
\item Game ticks to commands $t_n$ - the number of game ticks between the last two mouse positions
\item Distance to command - the distance travelled between the last two mouse positions
\begin{equation}
d_i = \sqrt{\delta x_{i}^2 + \delta y_{i}^2}
\end{equation} 
where $\delta x_i = x_{i+1} - x_i$ and $\delta y_i = y_{i+1} - y_i$
\end{itemize}

The total features of each level 3 action is shown in table \ref{tbl-level3features}, giving the total number of features as 38. 
\begin{table}[H]
\renewcommand*{\arraystretch}{1.5}
\centering
\begin{tabular}{| c | c | c |}
\hline
\textbf{Property} & \textbf{Features} & \textbf{Number of features} \\ \hline
Angle of movement & \multirow{9}{6cm}{Minimum, maximum, mean, standard deviation} & \multirow{9}{*}{$4 \times 9  = 36$} \\ \cline{1-1}
Curvature & & \\ \cline{1-1}
Rate of change of curvature & & \\ \cline{1-1}
Horizontal velocity & & \\ \cline{1-1}
Vertical velocity & & \\ \cline{1-1}
Velocity & & \\ \cline{1-1}
Acceleration & & \\ \cline{1-1}
Jerk & & \\ \cline{1-1}
Angular velocity & & \\ \hline
Game ticks to command & \multirow{2}{*}{Single value} & \multirow{2}{*}{2} \\ \cline{1-1}
Distance to command & & \\ \hline
\end{tabular}
\caption{Final processed features for each level 3 action}
\label{tbl-level3features}
\end{table}

\subsection{Game statistic features}
Another feature that was added for the machine learning models are game-specific statistics, which generally indicate the performance of a player, rather than purely their behaviour. 

The statistics are:
\begin{itemize}
\item Gold per minute
\item XP per minute
\item CS (creep score) per minute
\item Denies
\item Actions per minute
\item No. of move commands on target per minute
\item No. of move commands on position per minute
\item No. of attack commands on target per minute
\item No. of attack commands on position per minute
\item No. of spell cast commands on target per minute
\item No. of spell cast commands on position per minute
\item No. of spell cast commands with no target per minute
\item No. of hold position commands per minute
\end{itemize}
Most of these statistics are taken as per minute because the numbers can vary greatly depending on the length of the game. The number of denies is not taken per minute as denies typically only happen during the laning portion of a game, which always happens regardless of the length of the game. Further, the absolute number of denies is relatively low, with some players getting 0 denies often depending on their role in the team.

The gold, XP and creep score statistics are mainly a measure of performance. They are typically strong indicators for match outcome, as previous studies have shown \cite{dota-mixed-rank-win, dota-kinkade, dota-pu-yang, dota-yang} as winning teams have high gold and XP compared to losing teams. In this regard, they are likely less useful compared to other statistics, but can still provide behavioural information. The reason many Dota 2 statistics platform exist is for players to track their performance via numbers such as gold per minute and creep score per minute. Experienced players can typically reach higher numbers and players often have very similar performance across multiple matches. As such, it would be interesting to see how useful these statistics are compared to the other statistics. The other statistics are likely to be more reflective of player behaviour, as they are a measure how a player would control their hero during a match. As mentioned in section \ref{sec:dota-control}, there are multiple methods a player can use to accomplish the same actions in the game. The action statistics such as attack commands on target and attack commands on position are an indication of the different methods of control. TODO

There are some obvious statistics that were omitted from this feature set. The most obvious is the number of kills, deaths and assists (KDA) for the player. This was omitted because the KDA stats varies for the same player depending on their personal performance, and the performance of their team for a single game. Further, it is not uncommon for different players to have similar KDA statistics as there is not a large range of values for the number of kills, deaths and assists, making the stats unlikely to be very useful in player prediction. However, it is still interesting to see and prove that the KDA is not useful by evaluating models that use it, compared to models that don't. For this reason, this statistic is still kept accessible for the future. 


\subsection{Game itemisation features}
As it was seen in previous studies on using Dota 2 match data \cite{dota-gao, dota-eggert}, the items purchased by players is a strong indicator to the hero and role of the player. This is because different roles and heroes in the game will purchase different items that fit that role. By itself, the itemisation is not telling of who the player is, as multiple players playing the same hero are likely to buy similar items to each other. However, the same items can be placed in different inventory positions for different players. This is related to how a player's controls are set up, with each inventory position corresponding to a hotkey, which is typically a personal and custom choice by a player. Moreover, many items in Dota 2 have active abilities - such as the \textit{Blink dagger}, which teleports the player's character a short distance - providing the player with additional abilities that may be cast. As such, the location an item occupies in a player's inventory reflects the player control settings and is an easy feature that can differentiate different players. It is also unlikely a player changes their control settings, especially in the short term, meaning a pattern found TODO. 

\imagefig{0.35\textwidth}{imgs/inventory.png}{Example of the inventory with different items in Dota 2. The letters next to the items indicate they can be activated by pressing that key on the keyboard, which is bound to the position in the inventory, and is item-agnostic.}

The item names and inventory positions can be easily extracted at any game tick from the match replays. There are two areas of concern for this feature: when to sample for item positions and how to encode this information into numerical data. 

The problem of encoding the item data is more complicated, the information of which items were purchased and which inventory position they occupied had to be represented as a numeric value. This was tricky, as just using a numeric values such as the item id implies a relation between the items that is false. For example, item 1 is the blink dagger and item 2 is the blades of attack. Using the item ids for encoding would imply that the blink dagger is 1 value less than the blades of attack where in reality it is illogical to rank them this way as they qualitatively very different - the blink dagger costs more gold and provides an active ability, while the blades of attack costs less gold but provides additional bonuses to the player. 


\subsubsection{Feature hashing}
One method for encoding categorical features is to hash the features into a number of new features \cite{feature-hashing}. This provides a unique numeric value for each possible category, spread over a controllable number of features. This method is better than a simple numeric conversion in that TODO. However, it still suffers from the same issue of the hashed values not well representing categorical values. 

\subsubsection{One-hot encoding}
One-hot encoding is a well known and widely used approach to encode categorical values. It works by encoding each possible category as a separate binary feature, with a value of 0 or 1 representing the existence of the original value. There is no concern with the numeric values misrepresenting the categorical values because each value creates its own feature. The issue with this encoding method is the number of values to encode. Ideally, each combination of item and inventory position is encoded as unique value, which gives about 1800 binary features (\textasciitilde{}300 items $\times$ 6 inventory locations). 

\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\begin{figure}[H]
\centering
\begin{subfigure}{1\textwidth}
\centering
\begin{tabular}{| c | c | c | c | c | c |}
\hline
Slot 1 & Slot 2 & Slot 3 & Slot 4 & Slot 5 & Slot 6 \\ \hline
item\_tango & item\_blink & item\_empty & item\_empty & item\_phase\_boots & item\_manta \\ \hline
\end{tabular}
\caption{Raw item slots and names extracted from a match replay.}
\end{subfigure}

\vspace*{1cm}

\begin{subfigure}{1\textwidth}
\begin{tabular}{| L{2cm} | L{2cm} | L{2cm} | c | L{2cm} | L{2cm} | L{2cm} | c |}
\hline
Slot 1 item\_tango & Slot 2 item\_tango & Slot 3 item\_tango & ... & Slot 1 item\_blink & Slot 2 item\_blink & ... \\ \hline
1 & 0 & 0 & ... & 0 & 1 & ... \\ \hline
\end{tabular}
\caption{One-hot encoded items}
\end{subfigure}
\caption{Example of one-hot encoding inventory items.}
\end{figure}

Depending on the type of machine learning model used, the large number of features created from using one-hot encoding may not negatively affect the accuracy those models. However, it will be computationally expensive, both for storing the pre-processed data and for training the models. 


\subsubsection{Selective one-hot encoding}
To alleviate the issues of one-hot encoding generating too many features, the number of items used as features were restricted heuristically based on domain-specific knowledge of how Dota 2 plays as a game. The restrictions do not cause large loss of information. On the contrary, more information may be gained as the restrictions are chosen based on game knowledge. The two restrictions are as follows:
\begin{enumerate}
\item \textbf{Starting items only} - Every player starts a match of Dota 2 with the same amount of starting gold. This small amount of gold severely limits the number of items that can be purchased at the start of every match, bringing the number of items down from over 300 to about 30. Further, items that players buy at other points of a match are influenced to a greater extent by factors other than behaviour, such as whether a team is winning or losing. These factors are less influential (though they still exist) at the start of a match. The characteristic of different players placing items in different inventory slots still apply to starting items as a player's keyboard shortcuts for each inventory slot do not change. By restricting the items to only starting items, less features are created which reduce the computational load and there is less external influence, while still retaining the characteristic of player behaviour based on item selection. 
\item \textbf{Boots only} - Another telling aspect of the player identity is the inventory slot they place their boots in. In Dota 2, almost all players and heroes will buy a boots item, as it increases their movement speed. There are 5 types of advanced boots and 1 base boots item, making only 6 items (or 36 features) when only using boots. 
\end{enumerate}


% Heuristic for which items we think are most useful and only encode those


\subsubsection{Item differences}
A simple solution without the need to use an encoding scheme is to look at the differences in the items between the two matches being compared. This feature is very simple to encode, creating exactly one feature for each inventory slot. The idea here is if the player inventory of two matches contain the same items on the same slots, it is likely that the two matches belong to the same player. This approach is good and straightforward, encoding the exact information about item differences between players. However, there is significant loss of information as well. Any details about which items are in the inventory is lost. TODO
 
% advantage: simple to encode, shows difference information
% disadvantage: lose information on exact item

\subsection{Data collection}\label{sec:data-collection}
To download the replays, a combination of the OpenDota \cite{opendota} API and Valve's official API was used. The OpenDota API was used to fetch a list of players and their match history given a number of conditions. This allowed the replays downloaded to be controlled in a very specific way. For example, the game mode and hero id were specified to ensure all matches returned by the API are from the same player, in the same game mode and playing the same hero. This control is important to isolate additional variables that may affect player behaviour. The game mode and hero played are especially important. Different game modes have slightly different rules, for example turbo mode where gold and experience gain is doubled. Keeping the hero chosen the same is also very important, as heroes themselves represent different playstyles, which would have a large impact on item choices and possibly on player mouse dynamics. Different heroes would also be more likely to play in a different role, which affects statistics such as gold gained and last hits on creeps. 

\begin{figure}[H]
\centering
\begin{tikzpicture}[>=stealth']
% Locations
\def\ClientToServer{++(6,0)}
\def\ServerToClient{++(-7,0)}
\def\ValveToClient{++(-12,0)}
\def\Lifeline{++(0,-10)}

% Lifelines
\path (0,0) node[draw] (Client) {Client}
      (7,0) node[draw] (Server) {OpenDota API}
      (12,0) node[draw] (Valve)  {Valve API};
\draw (Client) -- \Lifeline (Server) -- \Lifeline (Valve) -- \Lifeline;

% Blocks
\path (Server)
      ++(0,-1) node (BeginHeroes) {} node[below right] {\texttt{\ /heroes}}
      ++(0,-1) node (EndHeroes)   {};
\filldraw[fill=blue!30] (BeginHeroes.west) rectangle (EndHeroes.east);

\path (Server)
      ++(0,-3.25) node (BeginPlayer) {} node[below right] {\texttt{\ /players}}
      ++(0,-1) node (EndPlayer) {};
\filldraw[fill=red!30] (BeginPlayer.west) rectangle (EndPlayer.east);

\path (Server)
      ++(0,-5.5) node (BeginMatches) {} node[below right] {\texttt{\ /matches}}
      ++(0,-1) node (EndMatches) {};
\filldraw[fill=green!30] (BeginMatches.west) rectangle (EndMatches.east);

\path (Valve)
      ++(0,-7.75) node (BeginReplays) {} node[below right] {\ Replay cluster}
      ++(0,-1) node (EndReplays) {};
\filldraw[fill=black!30] (BeginReplays.west) rectangle (EndReplays.east);


% Calls
\draw[->] (BeginHeroes)\ServerToClient -- node[above] {\texttt{hero\_id}} (BeginHeroes);
\draw[->] (EndHeroes) -- node[above] {List of player ids} \ServerToClient;

\draw[->] (BeginPlayer)\ServerToClient -- node[above] {\texttt{player\_id, gamemode, hero\_id}} (BeginPlayer);
\draw[->] (EndPlayer) -- node[above] {List of match ids} \ServerToClient;

\draw[->] (BeginMatches)\ServerToClient -- node[above] {\texttt{match\_id}} (BeginMatches);
\draw[->] (EndMatches) -- node[above] {Replay cluster and salt} \ServerToClient;

\draw[->] (BeginReplays)\ValveToClient -- node[above] {\texttt{cluster\_id, salt}} (BeginReplays);
\draw[->] (EndReplays) -- node[above] {\texttt{.dem} replay file} \ValveToClient;

\end{tikzpicture}
\caption{Sequence of API calls to download  replay files}
\label{fig:api-calls}
\end{figure}

Figure \ref{fig:api-calls} shows the sequence of API calls that lead to acquiring the replay file from Valve servers. Multiple calls to the OpenDota API are required as each call returns the data needed for the next. This whole process is streamlined as a Node.js script, which takes three parameters: hero id, number of players and number of games per player. Other parameters such as the game mode are defined in the script as they were kept constant for all the datasets. The list of constant parameters are as follows:
\begin{itemize}
\item Game mode - This was kept constant as the \textit{All Pick} game mode for all the datasets collected.
\item Team - Kept constant as \textit{Radiant}
\item Hero id - This was different for each dataset. In fact, the hero id defined the dataset as all other parameters were the same. 
\item Date - An addition added later in the project due to a large game changing patch. All matches downloaded were filtered to before the 18th of November 2018, to avoid changes from patch 7.20 affecting the existing work done. 
\end{itemize}
Occasionally, the replay files were not found as they may have been deleted, or the cluster where they are stored was unreachable. This was not an issue, as there is a large number of other players and replays that can be downloaded instead. The only implication is the number of replays downloaded may not be the exact number of replays specified (number of players $\times$ number of games per player).

\subsection{Data processing}

\subsubsection{Replay parsing}
The data processing is done using the parser \texttt{clarity} \cite{clarity}. It is an open source tool developed by Martin Schrodt that parses and extracts in game data from a replay file. The overwhelming amount of data available in a single game means the parser acts as an interface to access any entity or combat log. In some cases, the data is provided as an original protobuf object. The data gathered is output as a csv. For the forensic mouse movements, each row represents a level 3 action, giving thousands of level 3 actions for every game. On the other hand, there is only one set of game-specific features for each game, so there is only one row of game-specific features for each game.

\subsubsection{Further preprocessing}
pandas


\subsection{Machine learning overview}
The main goal of this project was to predict who the player is in a match of Dota 2. Naturally, this can be viewed as a classification problem to determine the player. However, there are small nuances in framing the problem, which leads to two different questions asked:

\begin{enumerate}
\item \textit{Given a match of Dota 2, who is the player playing this hero?}
\item \textit{Given two matches of Dota 2, is it the same player playing on this hero?}
\end{enumerate}

As mentioned earlier, the chosen hero was kept constant to avoid additional variables affecting the extracted features. The two questions ask subtly different things, and it is important to understand their differences, especially when it comes to what the input and output to the machine learning problem should be. 

For the first question, the input is a single match of Dota 2 and the output is the identity of the player. This can be viewed as either a binary classification task by focussing on the identity of a single player, or a multi-class classification task by looking at a pool of players. This is an interesting problem, as it can show whether certain features, or combination of features are able to identify one player's behaviour against other different players. It is the same problem that Liu et al. \cite{starcraft-identification} posed for the identification of Starcraft 2 players. Nevertheless, there is a fundamental limitation with this approach, and that is the generalisability of such a trained model on unseen players. In particular, a model trained to answer this question must be re-trained to identify a different player in the binary classification case, or re-trained on a different pool of players in the multi-class classification case. Either way, it cannot generalise to the broad playerbase of Dota 2 and predict on any player without re-training. This is what the second question attempts to answer. Instead of being restricted to work only on known players, a successful model that answers this question should be able to predict on any two matches. In theory, the models learn on the features of both matches and any pattern that may differentiate two different players. This can still be viewed as a binary classification task, with two matches from the same player in one class, and two matches from different players in the other. 

Further explanation on the details and results of each question are detailed in their respective sections (sections \ref{sec:game-classification} and \ref{sec:pair-classification}), along with discussion and analysis of why some features and models performed better than others 


\end{document}
